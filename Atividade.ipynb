{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5707ad",
   "metadata": {},
   "source": [
    "# Desafio de Previsão de Sucesso de Startups\n",
    "## Modelo Preditivo para Identificação de Startups de Sucesso\n",
    "\n",
    "### Autor: Rafael Santana Rodrigues\n",
    "### Data: Setembro 2025\n",
    "\n",
    "### Visão Geral do Projeto\n",
    "\n",
    "Este projeto desenvolve um modelo de machine learning para prever o sucesso de startups com base em dados históricos de financiamento, localização, setor de atuação e marcos alcançados. O objetivo é apoiar aceleradoras e investidores na tomada de decisões estratégicas.\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "- **Principal**: Criar um modelo com acurácia ≥ 80% para classificação binária de sucesso/insucesso\n",
    "- **Secundário**: Identificar os fatores mais importantes para o sucesso de startups\n",
    "\n",
    "### Tecnologias Utilizadas\n",
    "\n",
    "**Bibliotecas (conforme especificação do desafio):**\n",
    "- `numpy` - Computação numérica\n",
    "- `pandas` - Manipulação de dados\n",
    "- `scikit-learn` - Machine learning (foco em `sklearn.ensemble`)\n",
    "\n",
    "**Modelos Implementados:**\n",
    "- RandomForestClassifier \n",
    "- GradientBoostingClassifier\n",
    "- VotingClassifier (ensemble)\n",
    "\n",
    "### Dataset\n",
    "\n",
    "**Características:**\n",
    "- **Linhas**: 646 (treino) + 277 (teste)\n",
    "- **Features**: 32 variáveis preditoras\n",
    "- **Target**: Binária (0=insucesso, 1=sucesso)\n",
    "- **Balanceamento**: 64.7% sucesso vs 35.3% insucesso\n",
    "\n",
    "**Principais Variáveis:**\n",
    "- `funding_total_usd` - Total captado em USD\n",
    "- `relationships` - Número de relacionamentos\n",
    "- `funding_rounds` - Número de rodadas de captação\n",
    "- `is_CA`, `is_NY`, etc. - Localização por estado\n",
    "- `has_roundA`, `has_roundB`, etc. - Rodadas específicas\n",
    "- `category_code` - Setor de atuação\n",
    "\n",
    "### **Formulação de Hipóteses**\n",
    "\n",
    "**H1: Funding e Relacionamentos**\n",
    "> Startups com maior valor captado e mais relacionamentos têm maior probabilidade de sucesso\n",
    "\n",
    "**H2: Localização Estratégica**\n",
    "> Startups em hubs de inovação (CA) têm maior taxa de sucesso\n",
    "\n",
    "**H3: Maturidade de Financiamento**\n",
    "> Startups com múltiplas rodadas demonstram maior probabilidade de sucesso\n",
    "\n",
    "### Como Executar\n",
    "\n",
    "#### Notebook Jupyter\n",
    "```bash\n",
    "jupyter notebook startup_success_prediction.ipynb\n",
    "```\n",
    "\n",
    "#### Pré-requisitos\n",
    "```bash\n",
    "pip install numpy pandas scikit-learn\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acab8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4382d",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8af4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMAÇÕES GERAIS DOS DATASETS ===\n",
      "Dataset de treino: (646, 33)\n",
      "Dataset de teste: (277, 32)\n",
      "Submissão modelo: (277, 2)\n",
      "\n",
      "=== DISTRIBUIÇÃO DA VARIÁVEL TARGET ===\n",
      "Sucesso (1): 418 (64.7%)\n",
      "Insucesso (0): 228 (35.3%)\n",
      "\n",
      "=== ANÁLISE DE VALORES NULOS ===\n",
      "age_first_milestone_year: 138 (21.4%)\n",
      "age_last_milestone_year: 111 (17.2%)\n",
      "age_first_funding_year: 35 (5.4%)\n",
      "age_last_funding_year: 9 (1.4%)\n",
      "\n",
      "=== ESTATÍSTICAS DESCRITIVAS ===\n",
      "               id  age_first_funding_year  age_last_funding_year  \\\n",
      "count  646.000000              611.000000             637.000000   \n",
      "mean   461.577399                2.341718               4.037724   \n",
      "std    264.859464                2.468275               2.950923   \n",
      "min      1.000000                0.000000               0.000000   \n",
      "25%    233.250000                0.680000               1.870000   \n",
      "50%    459.500000                1.650000               3.610000   \n",
      "75%    692.500000                3.600000               5.590000   \n",
      "max    923.000000               21.900000              21.900000   \n",
      "\n",
      "       age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "count                508.000000               535.000000     646.000000   \n",
      "mean                   3.352657                 4.944729       7.948916   \n",
      "std                    2.866952                 3.213319       7.397602   \n",
      "min                    0.000000                 0.000000       0.000000   \n",
      "25%                    1.185000                 2.540000       3.000000   \n",
      "50%                    2.785000                 4.620000       6.000000   \n",
      "75%                    4.935000                 6.880000      10.000000   \n",
      "max                   24.680000                24.680000      63.000000   \n",
      "\n",
      "       funding_rounds  funding_total_usd  milestones       is_CA  ...  \\\n",
      "count      646.000000       6.460000e+02  646.000000  646.000000  ...   \n",
      "mean         2.351393       2.949633e+07    1.913313    0.546440  ...   \n",
      "std          1.357856       2.261999e+08    1.337095    0.498224  ...   \n",
      "min          1.000000       1.100000e+04    0.000000    0.000000  ...   \n",
      "25%          1.000000       3.000000e+06    1.000000    0.000000  ...   \n",
      "50%          2.000000       1.020000e+07    2.000000    1.000000  ...   \n",
      "75%          3.000000       2.587500e+07    3.000000    1.000000  ...   \n",
      "max          8.000000       5.700000e+09    6.000000    1.000000  ...   \n",
      "\n",
      "       is_consulting  is_othercategory      has_VC   has_angel  has_roundA  \\\n",
      "count     646.000000        646.000000  646.000000  646.000000  646.000000   \n",
      "mean        0.003096          0.304954    0.329721    0.260062    0.515480   \n",
      "std         0.055598          0.460745    0.470476    0.439008    0.500148   \n",
      "min         0.000000          0.000000    0.000000    0.000000    0.000000   \n",
      "25%         0.000000          0.000000    0.000000    0.000000    0.000000   \n",
      "50%         0.000000          0.000000    0.000000    0.000000    1.000000   \n",
      "75%         0.000000          1.000000    1.000000    1.000000    1.000000   \n",
      "max         1.000000          1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "       has_roundB  has_roundC  has_roundD  avg_participants      labels  \n",
      "count  646.000000  646.000000  646.000000        646.000000  646.000000  \n",
      "mean     0.419505    0.235294    0.091331          2.848655    0.647059  \n",
      "std      0.493860    0.424511    0.288303          1.894050    0.478255  \n",
      "min      0.000000    0.000000    0.000000          1.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000          1.500000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000          2.333300    1.000000  \n",
      "75%      1.000000    0.000000    0.000000          4.000000    1.000000  \n",
      "max      1.000000    1.000000    1.000000         16.000000    1.000000  \n",
      "\n",
      "[8 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Carregamento dos dados\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(\"=== INFORMAÇÕES GERAIS DOS DATASETS ===\")\n",
    "print(f\"Dataset de treino: {train_df.shape}\")\n",
    "print(f\"Dataset de teste: {test_df.shape}\")\n",
    "print(f\"Submissão modelo: {sample_submission.shape}\")\n",
    "\n",
    "# Análise da variável target\n",
    "print(\"\\n=== DISTRIBUIÇÃO DA VARIÁVEL TARGET ===\")\n",
    "target_dist = train_df['labels'].value_counts()\n",
    "print(f\"Sucesso (1): {target_dist[1]} ({target_dist[1]/len(train_df)*100:.1f}%)\")\n",
    "print(f\"Insucesso (0): {target_dist[0]} ({target_dist[0]/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "# Verificação de valores nulos\n",
    "print(\"\\n=== ANÁLISE DE VALORES NULOS ===\")\n",
    "null_analysis = train_df.isnull().sum()\n",
    "null_analysis = null_analysis[null_analysis > 0].sort_values(ascending=False)\n",
    "for col, count in null_analysis.items():\n",
    "    print(f\"{col}: {count} ({count/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "# Estatísticas descritivas das variáveis numéricas\n",
    "print(\"\\n=== ESTATÍSTICAS DESCRITIVAS ===\")\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "print(train_df[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e800fc",
   "metadata": {},
   "source": [
    "## 3. Formulação de Hipóteses\n",
    "\n",
    "Com base na análise exploratória, formulo as seguintes **três hipóteses**:\n",
    "\n",
    "### **Hipótese 1: Funding e Relacionamentos**\n",
    "*Startups com maior valor total captado (funding_total_usd) e mais relacionamentos (relationships) têm maior probabilidade de sucesso.*\n",
    "\n",
    "**Justificativa:** O acesso a capital e uma rede robusta de relacionamentos (investidores, mentores, parceiros) são fatores críticos para o crescimento e sustentabilidade de startups.\n",
    "\n",
    "### **Hipótese 2: Localização Estratégica** \n",
    "*Startups localizadas em hubs de inovação como Califórnia (is_CA) têm maior taxa de sucesso devido ao ecossistema favorável.*\n",
    "\n",
    "**Justificativa:** Regiões como Silicon Valley oferecem acesso privilegiado a investidores, talentos e mercados, criando um ambiente propício ao sucesso.\n",
    "\n",
    "### **Hipótese 3: Maturidade de Financiamento**\n",
    "*Startups que passaram por múltiplas rodadas de investimento (has_roundA, has_roundB, has_roundC) demonstram maior probabilidade de sucesso, indicando validação progressiva do modelo de negócio.*\n",
    "\n",
    "**Justificativa:** O progresso através de diferentes rodadas de investimento indica tração, crescimento e confiança progressiva dos investidores.\n",
    "\n",
    "## 4. Análise das Hipóteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95746a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDAÇÃO DAS HIPÓTESES ===\n",
      "\n",
      "--- Hipótese 1: Funding e Relacionamentos ---\n",
      "Funding médio - Insucesso: $16,130,875 | Sucesso: $36,786,578\n",
      "Relacionamentos médios - Insucesso: 4.5 | Sucesso: 9.8\n",
      "\n",
      "--- Hipótese 2: Localização (Califórnia) ---\n",
      "Taxa de sucesso CA: 69.1%\n",
      "Taxa de sucesso outros estados: 59.4%\n",
      "\n",
      "--- Hipótese 3: Múltiplas Rodadas ---\n",
      "Taxa de sucesso por número de rodadas:\n",
      "0 rodadas: 42.9%\n",
      "1 rodadas: 64.6%\n",
      "2 rodadas: 77.6%\n",
      "3 rodadas: 86.4%\n",
      "4 rodadas: 85.0%\n"
     ]
    }
   ],
   "source": [
    "# Verificação das hipóteses\n",
    "print(\"=== VALIDAÇÃO DAS HIPÓTESES ===\")\n",
    "\n",
    "# Hipótese 1: Funding e Relacionamentos\n",
    "print(\"\\n--- Hipótese 1: Funding e Relacionamentos ---\")\n",
    "funding_success = train_df.groupby('labels')['funding_total_usd'].mean()\n",
    "relationships_success = train_df.groupby('labels')['relationships'].mean()\n",
    "print(f\"Funding médio - Insucesso: ${funding_success[0]:,.0f} | Sucesso: ${funding_success[1]:,.0f}\")\n",
    "print(f\"Relacionamentos médios - Insucesso: {relationships_success[0]:.1f} | Sucesso: {relationships_success[1]:.1f}\")\n",
    "\n",
    "# Hipótese 2: Localização (Califórnia)\n",
    "print(\"\\n--- Hipótese 2: Localização (Califórnia) ---\")\n",
    "ca_success_rate = train_df[train_df['is_CA'] == 1]['labels'].mean()\n",
    "other_success_rate = train_df[train_df['is_CA'] == 0]['labels'].mean()\n",
    "print(f\"Taxa de sucesso CA: {ca_success_rate:.1%}\")\n",
    "print(f\"Taxa de sucesso outros estados: {other_success_rate:.1%}\")\n",
    "\n",
    "# Hipótese 3: Múltiplas rodadas\n",
    "print(\"\\n--- Hipótese 3: Múltiplas Rodadas ---\")\n",
    "round_columns = ['has_roundA', 'has_roundB', 'has_roundC', 'has_roundD']\n",
    "train_df['total_rounds'] = train_df[round_columns].sum(axis=1)\n",
    "rounds_success = train_df.groupby('total_rounds')['labels'].mean()\n",
    "print(\"Taxa de sucesso por número de rodadas:\")\n",
    "for rounds, rate in rounds_success.items():\n",
    "    print(f\"{rounds} rodadas: {rate:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc85d01",
   "metadata": {},
   "source": [
    "## 5. Limpeza e Tratamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1cd46a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LIMPEZA E PREPARAÇÃO DOS DADOS ===\n",
      "Dados de treino após limpeza: (646, 37)\n",
      "Dados de teste após limpeza: (277, 35)\n",
      "Valores nulos restantes no treino: 0\n"
     ]
    }
   ],
   "source": [
    "def clean_and_prepare_data(df, is_train=True):\n",
    "    \"\"\"\n",
    "    Função para limpeza e preparação dos dados\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Remover coluna ID (não é feature)\n",
    "    if 'id' in df_clean.columns:\n",
    "        df_clean = df_clean.drop('id', axis=1)\n",
    "    \n",
    "    # Tratamento de valores nulos para variáveis de idade\n",
    "    age_columns = ['age_first_funding_year', 'age_last_funding_year', \n",
    "                   'age_first_milestone_year', 'age_last_milestone_year']\n",
    "    \n",
    "    # Estratégia: imputar com mediana (mais robusta a outliers)\n",
    "    for col in age_columns:\n",
    "        if col in df_clean.columns:\n",
    "            median_val = df_clean[col].median()\n",
    "            df_clean[col] = df_clean[col].fillna(median_val)\n",
    "    \n",
    "    # Tratamento de funding_total_usd (se houver nulos)\n",
    "    if 'funding_total_usd' in df_clean.columns:\n",
    "        df_clean['funding_total_usd'] = df_clean['funding_total_usd'].fillna(\n",
    "            df_clean['funding_total_usd'].median()\n",
    "        )\n",
    "    \n",
    "    # Codificação da variável categórica category_code\n",
    "    if 'category_code' in df_clean.columns:\n",
    "        # Label Encoding para category_code\n",
    "        le = LabelEncoder()\n",
    "        df_clean['category_code_encoded'] = le.fit_transform(df_clean['category_code'].fillna('unknown'))\n",
    "        df_clean = df_clean.drop('category_code', axis=1)\n",
    "    \n",
    "    # Criar features derivadas\n",
    "    df_clean['funding_per_round'] = df_clean['funding_total_usd'] / (df_clean['funding_rounds'] + 1)\n",
    "    df_clean['milestones_per_relationship'] = df_clean['milestones'] / (df_clean['relationships'] + 1)\n",
    "    \n",
    "    # Feature: soma total de rodadas\n",
    "    round_cols = ['has_roundA', 'has_roundB', 'has_roundC', 'has_roundD']\n",
    "    df_clean['total_funding_rounds'] = df_clean[round_cols].sum(axis=1)\n",
    "    \n",
    "    # Feature: tem financiamento\n",
    "    df_clean['has_funding'] = (df_clean['has_VC'] | df_clean['has_angel']).astype(int)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicar limpeza\n",
    "print(\"=== LIMPEZA E PREPARAÇÃO DOS DADOS ===\")\n",
    "train_clean = clean_and_prepare_data(train_df, is_train=True)\n",
    "test_clean = clean_and_prepare_data(test_df, is_train=False)\n",
    "\n",
    "print(f\"Dados de treino após limpeza: {train_clean.shape}\")\n",
    "print(f\"Dados de teste após limpeza: {test_clean.shape}\")\n",
    "\n",
    "# Verificar se ainda há valores nulos\n",
    "remaining_nulls = train_clean.isnull().sum().sum()\n",
    "print(f\"Valores nulos restantes no treino: {remaining_nulls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ddee1c",
   "metadata": {},
   "source": [
    "## 6. Seleção de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb0cb6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SELEÇÃO DE FEATURES ===\n",
      "Features selecionadas: 35\n",
      "Dimensões finais - X: (646, 35), Test: (277, 35)\n",
      "Features prioritárias identificadas: 18\n"
     ]
    }
   ],
   "source": [
    "# Separar features e target\n",
    "if 'labels' in train_clean.columns:\n",
    "    X = train_clean.drop('labels', axis=1)\n",
    "    y = train_clean['labels']\n",
    "else:\n",
    "    X = train_clean\n",
    "    y = train_df['labels']\n",
    "\n",
    "# Garantir que test tenha as mesmas colunas que train\n",
    "common_features = X.columns.intersection(test_clean.columns)\n",
    "X = X[common_features]\n",
    "test_final = test_clean[common_features]\n",
    "\n",
    "print(\"=== SELEÇÃO DE FEATURES ===\")\n",
    "print(f\"Features selecionadas: {len(common_features)}\")\n",
    "print(f\"Dimensões finais - X: {X.shape}, Test: {test_final.shape}\")\n",
    "\n",
    "# Lista das features mais importantes baseadas nas hipóteses\n",
    "priority_features = [\n",
    "    'funding_total_usd', 'relationships', 'funding_rounds',\n",
    "    'is_CA', 'is_NY', 'is_MA', 'is_TX',\n",
    "    'has_roundA', 'has_roundB', 'has_roundC', 'has_roundD',\n",
    "    'has_VC', 'has_angel', 'milestones', 'avg_participants',\n",
    "    'total_funding_rounds', 'has_funding', 'funding_per_round'\n",
    "]\n",
    "\n",
    "print(f\"Features prioritárias identificadas: {len([f for f in priority_features if f in X.columns])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4e96c",
   "metadata": {},
   "source": [
    "## 7. Construção e Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd6abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONSTRUÇÃO DOS MODELOS ===\n",
      "Treino: (516, 35), Validação: (130, 35)\n",
      "\n",
      "--- RandomForest ---\n",
      "Acurácia: 0.7615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.54      0.62        46\n",
      "           1       0.78      0.88      0.83        84\n",
      "\n",
      "    accuracy                           0.76       130\n",
      "   macro avg       0.75      0.71      0.72       130\n",
      "weighted avg       0.76      0.76      0.75       130\n",
      "\n",
      "\n",
      "--- GradientBoosting ---\n",
      "Acurácia: 0.8077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.61      0.69        46\n",
      "           1       0.81      0.92      0.86        84\n",
      "\n",
      "    accuracy                           0.81       130\n",
      "   macro avg       0.81      0.76      0.78       130\n",
      "weighted avg       0.81      0.81      0.80       130\n",
      "\n",
      "\n",
      "--- ENSEMBLE MODEL ---\n",
      "Acurácia: 0.7846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.65        46\n",
      "           1       0.79      0.90      0.84        84\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.78      0.73      0.75       130\n",
      "weighted avg       0.78      0.78      0.78       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divisão treino/validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"=== CONSTRUÇÃO DOS MODELOS ===\")\n",
    "print(f\"Treino: {X_train.shape}, Validação: {X_val.shape}\")\n",
    "\n",
    "# Padronização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Modelos do ensemble\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=42, \n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Treinamento e avaliação dos modelos individuais\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Usar dados padronizados para GradientBoosting, originais para RandomForest\n",
    "    if name == 'GradientBoosting':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    results[name] = accuracy\n",
    "    \n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"Acurácia: {accuracy:.4f}\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Modelo ensemble (Voting Classifier)\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "y_pred_ensemble = ensemble_model.predict(X_val)\n",
    "ensemble_accuracy = accuracy_score(y_val, y_pred_ensemble)\n",
    "\n",
    "print(f\"\\n--- ENSEMBLE MODEL ---\")\n",
    "print(f\"Acurácia: {ensemble_accuracy:.4f}\")\n",
    "print(classification_report(y_val, y_pred_ensemble))\n",
    "\n",
    "results['Ensemble'] = ensemble_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8aff1f",
   "metadata": {},
   "source": [
    "## 8. Finetuning de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0691ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINETUNING DE HIPERPARÂMETROS ===\n",
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "Melhores parâmetros GradientBoosting: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Melhor score CV: 0.7908\n",
      "Acurácia do modelo otimizado: 0.7769\n",
      "Melhores parâmetros GradientBoosting: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Melhor score CV: 0.7908\n",
      "Acurácia do modelo otimizado: 0.7769\n",
      "Cross-validation scores: [0.80769231 0.76744186 0.79069767 0.82170543 0.73643411]\n",
      "CV média: 0.7848 (+/- 0.0604)\n",
      "Cross-validation scores: [0.80769231 0.76744186 0.79069767 0.82170543 0.73643411]\n",
      "CV média: 0.7848 (+/- 0.0604)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== FINETUNING DE HIPERPARÂMETROS ===\")\n",
    "\n",
    "# Definir grid de hiperparâmetros para GradientBoosting\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Grid Search para GradientBoosting\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_grid_gb,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Usar dados padronizados para GradientBoosting\n",
    "gb_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Melhores parâmetros GradientBoosting: {gb_grid.best_params_}\")\n",
    "print(f\"Melhor score CV: {gb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Avaliar modelo otimizado\n",
    "best_gb = gb_grid.best_estimator_\n",
    "y_pred_best = best_gb.predict(X_val_scaled)\n",
    "best_accuracy = accuracy_score(y_val, y_pred_best)\n",
    "\n",
    "print(f\"Acurácia do modelo otimizado: {best_accuracy:.4f}\")\n",
    "\n",
    "# Cross-validation do modelo final usando dados padronizados\n",
    "X_scaled_full = scaler.fit_transform(X)\n",
    "cv_scores = cross_val_score(best_gb, X_scaled_full, y, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"CV média: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f8aca",
   "metadata": {},
   "source": [
    "## 9. Importância das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "252915e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP 15 FEATURES MAIS IMPORTANTES ===\n",
      "                        feature  importance\n",
      "4                 relationships    0.329115\n",
      "6             funding_total_usd    0.115173\n",
      "3       age_last_milestone_year    0.097670\n",
      "0        age_first_funding_year    0.075739\n",
      "32  milestones_per_relationship    0.067103\n",
      "31            funding_per_round    0.061066\n",
      "7                    milestones    0.055879\n",
      "29             avg_participants    0.048212\n",
      "1         age_last_funding_year    0.042091\n",
      "2      age_first_milestone_year    0.027866\n",
      "5                funding_rounds    0.021473\n",
      "30        category_code_encoded    0.018053\n",
      "11                        is_TX    0.008357\n",
      "25                   has_roundA    0.006223\n",
      "22             is_othercategory    0.004700\n",
      "\n",
      "=== VALIDAÇÃO DAS HIPÓTESES ATRAVÉS DA IMPORTÂNCIA ===\n",
      "Hipótese 1 - Importância média: 0.1685\n",
      "Hipótese 2 - Importância média: 0.0028\n",
      "Hipótese 3 - Importância média: 0.0028\n"
     ]
    }
   ],
   "source": [
    "# Análise da importância das features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_gb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=== TOP 15 FEATURES MAIS IMPORTANTES ===\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Validação das hipóteses através da importância\n",
    "print(\"\\n=== VALIDAÇÃO DAS HIPÓTESES ATRAVÉS DA IMPORTÂNCIA ===\")\n",
    "hyp1_features = ['funding_total_usd', 'relationships', 'funding_per_round']\n",
    "hyp2_features = ['is_CA', 'is_NY', 'is_MA', 'is_TX']\n",
    "hyp3_features = ['has_roundA', 'has_roundB', 'has_roundC', 'total_funding_rounds']\n",
    "\n",
    "for i, features in enumerate([hyp1_features, hyp2_features, hyp3_features], 1):\n",
    "    avg_importance = feature_importance[\n",
    "        feature_importance['feature'].isin(features)\n",
    "    ]['importance'].mean()\n",
    "    print(f\"Hipótese {i} - Importância média: {avg_importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e1485",
   "metadata": {},
   "source": [
    "## 10. Geração das Predições Finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3f9edff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GERAÇÃO DAS PREDIÇÕES FINAIS ===\n",
      "DECISÃO: Usar GradientBoosting original devido à melhor performance\n",
      "GradientBoosting original: 0.8077\n",
      "GradientBoosting otimizado: 0.7769\n",
      "\n",
      "Predições geradas para 277 startups\n",
      "Distribuição das predições:\n",
      "Sucesso previsto: 191 (69.0%)\n",
      "Insucesso previsto: 86 (31.0%)\n",
      "\n",
      "=== RESUMO FINAL ===\n",
      "Modelo final escolhido: GradientBoosting Original\n",
      "Acurácia do modelo final: 0.8077\n",
      "Meta de 80% atingida: SIM\n",
      "\n",
      "=== COMPARAÇÃO COMPLETA ===\n",
      "GradientBoosting: 0.8077 MELHOR\n",
      "Ensemble: 0.7846 \n",
      "GradientBoosting Otimizado: 0.7769 \n",
      "RandomForest: 0.7615 \n",
      "\n",
      "Predições geradas para 277 startups\n",
      "Distribuição das predições:\n",
      "Sucesso previsto: 191 (69.0%)\n",
      "Insucesso previsto: 86 (31.0%)\n",
      "\n",
      "=== RESUMO FINAL ===\n",
      "Modelo final escolhido: GradientBoosting Original\n",
      "Acurácia do modelo final: 0.8077\n",
      "Meta de 80% atingida: SIM\n",
      "\n",
      "=== COMPARAÇÃO COMPLETA ===\n",
      "GradientBoosting: 0.8077 MELHOR\n",
      "Ensemble: 0.7846 \n",
      "GradientBoosting Otimizado: 0.7769 \n",
      "RandomForest: 0.7615 \n"
     ]
    }
   ],
   "source": [
    "print(\"=== GERAÇÃO DAS PREDIÇÕES FINAIS ===\")\n",
    "\n",
    "# Análise dos resultados: O GradientBoosting original (80.77%) teve melhor performance \n",
    "# que o otimizado (77.69%), então usaremos o original\n",
    "print(\"DECISÃO: Usar GradientBoosting original devido à melhor performance\")\n",
    "print(f\"GradientBoosting original: {results['GradientBoosting']:.4f}\")\n",
    "print(f\"GradientBoosting otimizado: {best_accuracy:.4f}\")\n",
    "\n",
    "# Usar o modelo GradientBoosting original como modelo final\n",
    "final_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Padronizar os dados completos para o GradientBoosting\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_final_scaled = scaler.transform(test_final.reindex(columns=X.columns, fill_value=0))\n",
    "\n",
    "# Treinar com todos os dados\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "# Predições finais\n",
    "final_predictions = final_model.predict(test_final_scaled)\n",
    "\n",
    "# Criar arquivo de submissão\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'labels': final_predictions\n",
    "})\n",
    "\n",
    "# Salvar arquivo de submissão\n",
    "submission.to_csv('startup_success_predictions.csv', index=False)\n",
    "\n",
    "print(f\"\\nPredições geradas para {len(submission)} startups\")\n",
    "print(f\"Distribuição das predições:\")\n",
    "print(f\"Sucesso previsto: {sum(final_predictions)} ({sum(final_predictions)/len(final_predictions)*100:.1f}%)\")\n",
    "print(f\"Insucesso previsto: {len(final_predictions) - sum(final_predictions)} ({(len(final_predictions) - sum(final_predictions))/len(final_predictions)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== RESUMO FINAL ===\")\n",
    "print(f\"Modelo final escolhido: GradientBoosting Original\")\n",
    "print(f\"Acurácia do modelo final: {results['GradientBoosting']:.4f}\")\n",
    "print(f\"Meta de 80% atingida: {'SIM' if results['GradientBoosting'] >= 0.8 else 'NÃO'}\")\n",
    "\n",
    "# Comparação de todos os modelos incluindo o otimizado\n",
    "print(f\"\\n=== COMPARAÇÃO COMPLETA ===\")\n",
    "all_results = results.copy()\n",
    "all_results['GradientBoosting Otimizado'] = best_accuracy\n",
    "\n",
    "for model_name, accuracy in sorted(all_results.items(), key=lambda x: x[1], reverse=True):\n",
    "    status = \"MELHOR\" if accuracy == max(all_results.values()) else \"\"\n",
    "    print(f\"{model_name}: {accuracy:.4f} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a822de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE DO FINETUNING DO GRADIENTBOOSTING ===\n",
      "GradientBoosting Original: 0.8077 (80.77%)\n",
      "GradientBoosting Otimizado: 0.7769 (77.69%)\n",
      "Diferença: -0.0308\n",
      "Conclusão: O modelo original teve MELHOR performance\n",
      "\n",
      "=== HIPERPARÂMETROS OTIMIZADOS ===\n",
      "learning_rate: 0.01\n",
      "max_depth: 3\n",
      "min_samples_leaf: 4\n",
      "min_samples_split: 2\n",
      "n_estimators: 200\n",
      "subsample: 0.9\n",
      "\n",
      "=== ANÁLISE DO RESULTADO ===\n",
      "Possíveis razões para a performance inferior do modelo otimizado:\n",
      "1. Os hiperparâmetros padrão já eram adequados para este dataset\n",
      "2. O modelo otimizado pode ter sofrido overfitting\n",
      "3. A busca em grid pode ter encontrado um mínimo local\n",
      "4. O dataset pode ser pequeno demais para beneficiar de hiperparâmetros mais complexos\n",
      "\n",
      "=== DECISION FINAL ===\n",
      "Modelo escolhido: GradientBoosting ORIGINAL\n",
      "Motivo: Melhor acurácia (0.8077 vs 0.7769)\n",
      "Status da meta 80%: ATINGIDA\n",
      "\n",
      "=== RANKING FINAL DE TODOS OS MODELOS ===\n",
      "1º Lugar - VENCEDOR: GradientBoosting - 0.8077\n",
      "2º Lugar: Ensemble - 0.7846\n",
      "3º Lugar: GradientBoosting Otimizado - 0.7769\n",
      "4º Lugar: RandomForest - 0.7615\n"
     ]
    }
   ],
   "source": [
    "## Análise dos Resultados do Finetuning\n",
    "\n",
    "### Comparação: GradientBoosting Original vs Otimizado\n",
    "print(\"=== ANÁLISE DO FINETUNING DO GRADIENTBOOSTING ===\")\n",
    "print(f\"GradientBoosting Original: {results['GradientBoosting']:.4f} (80.77%)\")\n",
    "print(f\"GradientBoosting Otimizado: {best_accuracy:.4f} (77.69%)\")\n",
    "print(f\"Diferença: {(best_accuracy - results['GradientBoosting']):.4f}\")\n",
    "print(f\"Conclusão: O modelo original teve MELHOR performance\")\n",
    "\n",
    "# Mostrar os hiperparâmetros testados\n",
    "print(f\"\\n=== HIPERPARÂMETROS OTIMIZADOS ===\")\n",
    "for param, value in gb_grid.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "print(f\"\\n=== ANÁLISE DO RESULTADO ===\")\n",
    "print(\"Possíveis razões para a performance inferior do modelo otimizado:\")\n",
    "print(\"1. Os hiperparâmetros padrão já eram adequados para este dataset\")\n",
    "print(\"2. O modelo otimizado pode ter sofrido overfitting\")\n",
    "print(\"3. A busca em grid pode ter encontrado um mínimo local\")\n",
    "print(\"4. O dataset pode ser pequeno demais para beneficiar de hiperparâmetros mais complexos\")\n",
    "\n",
    "print(f\"\\n=== DECISION FINAL ===\")\n",
    "print(\"Modelo escolhido: GradientBoosting ORIGINAL\")\n",
    "print(f\"Motivo: Melhor acurácia ({results['GradientBoosting']:.4f} vs {best_accuracy:.4f})\")\n",
    "print(f\"Status da meta 80%: {'ATINGIDA' if results['GradientBoosting'] >= 0.8 else 'NÃO ATINGIDA'}\")\n",
    "\n",
    "# Ranking final\n",
    "print(f\"\\n=== RANKING FINAL DE TODOS OS MODELOS ===\")\n",
    "all_results = results.copy()\n",
    "all_results['GradientBoosting Otimizado'] = best_accuracy\n",
    "\n",
    "sorted_results = sorted(all_results.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (model, acc) in enumerate(sorted_results, 1):\n",
    "    status = f\"{i}º Lugar\"\n",
    "    if i == 1:\n",
    "        status += \" - VENCEDOR\"\n",
    "    print(f\"{status}: {model} - {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5a4ff",
   "metadata": {},
   "source": [
    "## 11. Conclusões\n",
    "\n",
    "### Desempenho dos Modelos\n",
    "- **Melhor Modelo**: GradientBoosting Original com **80.77%** de acurácia\n",
    "- **Segundo lugar**: Ensemble Model com 78.46% de acurácia  \n",
    "- **Terceiro lugar**: GradientBoosting Otimizado com 77.69% de acurácia\n",
    "- **Quarto lugar**: RandomForest com 76.15% de acurácia\n",
    "\n",
    "### Insights sobre o Finetuning\n",
    "**Resultado Surpreendente**: O finetuning do GradientBoosting resultou em performance **inferior** ao modelo original:\n",
    "- **Original**: 80.77% de acurácia\n",
    "- **Otimizado**: 77.69% de acurácia (-3.08 pontos percentuais)\n",
    "\n",
    "**Possíveis explicações**:\n",
    "1. Os hiperparâmetros padrão já eram bem adequados para este dataset\n",
    "2. O modelo otimizado pode ter sofrido overfitting nos dados de validação\n",
    "3. O dataset pode ser pequeno demais para beneficiar de hiperparâmetros mais complexos\n",
    "4. A busca em grid encontrou um mínimo local subótimo\n",
    "\n",
    "### Validação das Hipóteses\n",
    "1. **Hipótese 1** (Funding e Relacionamentos): **CONFIRMADA** \n",
    "   - Features financeiras dominam o ranking de importância\n",
    "   - `relationships` é a feature mais importante (32.91% no modelo otimizado)\n",
    "   - `funding_total_usd` e `funding_per_round` estão entre as top 6\n",
    "   \n",
    "2. **Hipótese 2** (Localização): **PARCIALMENTE CONFIRMADA** \n",
    "   - Califórnia tem 69.1% vs 59.4% de taxa de sucesso em outros estados\n",
    "   - Porém, importância média das features de localização é baixa (0.28%)\n",
    "   \n",
    "3. **Hipótese 3** (Múltiplas Rodadas): **PARCIALMENTE CONFIRMADA**\n",
    "   - Clara progressão: 0 rodadas (42.9%) → 4 rodadas (85.0%)\n",
    "   - Porém, importância média dessas features é baixa (0.28%)\n",
    "\n",
    "### Principais Insights do Modelo Vencedor\n",
    "1. **Relationships** (32.91%): A rede de relacionamentos é EXTREMAMENTE crítica\n",
    "2. **Funding metrics**: Valor total de funding é o segundo fator mais importante\n",
    "3. **Age variables**: Tempo de marcos e financiamento são muito relevantes\n",
    "4. **Derived features**: Features criadas agregaram valor significativo\n",
    "\n",
    "### Meta Atingida\n",
    "- **Objetivo**: Acurácia ≥ 80%\n",
    "- **Resultado**: 80.77% com GradientBoosting Original\n",
    "- **Status**: **ATINGIDA** (+0.77 pontos percentuais acima da meta)\n",
    "\n",
    "### Lições Aprendidas\n",
    "1. **Nem sempre o finetuning melhora a performance** - às vezes os defaults são ótimos\n",
    "2. **Simplicidade pode ser melhor** - modelos mais complexos nem sempre são superiores\n",
    "3. **Validação é crucial** - sempre comparar modelo original vs otimizado\n",
    "\n",
    "### Recomendações Estratégicas para Aceleradoras\n",
    "1. **Priorizar startups** com redes robustas de relacionamentos (fator mais crítico)\n",
    "2. **Avaliar capacidade de captação** - funding total é determinante\n",
    "3. **Considerar tempo de mercado** - age variables são importantes\n",
    "4. **Não superestimar localização** - menos importante que esperado\n",
    "5. **Usar GradientBoosting com parâmetros padrão** para screening inicial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
